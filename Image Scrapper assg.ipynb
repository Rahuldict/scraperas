{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4505906-04fb-4ba2-9df5-ec48c497d936",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40086489-f260-4ed6-915c-ae2e20fae25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 = Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c86a673-ff92-4d89-b161-f6b0b5536026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdfc6ac-57b0-4708-8886-02f59604b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the URL of the YouTube channel you want to extract videos from\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the channel URL and parse the HTML content\n",
    "response = requests.get(channel_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all the video links on the channel page\n",
    "video_links = soup.find_all(\"a\", {\"class\": \"yt-simple-endpoint style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "first_five_video_urls = []\n",
    "for link in video_links[:5]:\n",
    "    video_url = \"https://www.youtube.com\" + link[\"href\"]\n",
    "    first_five_video_urls.append(video_url)\n",
    "\n",
    "# Print the video URLs\n",
    "for idx, video_url in enumerate(first_five_video_urls, start=1):\n",
    "    print(f\"Video {idx}: {video_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd76b8ad-898f-4f35-a6b2-7bc0d5700e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345ff3a9-94b8-47bd-9c08-183915377a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the URL of the YouTube channel you want to extract videos from\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the channel URL and parse the HTML content\n",
    "response = requests.get(channel_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all the video thumbnail elements on the channel page\n",
    "thumbnail_elements = soup.find_all(\"img\", {\"class\": \"style-scope yt-img-shadow\"})\n",
    "\n",
    "# Extract the thumbnail URLs of the first five videos\n",
    "first_five_thumbnail_urls = []\n",
    "for thumbnail in thumbnail_elements[:5]:\n",
    "    thumbnail_url = thumbnail[\"src\"]\n",
    "    first_five_thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Print the thumbnail URLs\n",
    "for idx, thumbnail_url in enumerate(first_five_thumbnail_urls, start=1):\n",
    "    print(f\"Thumbnail {idx}: {thumbnail_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15790c3-3e5d-4ea7-bb43-4e427f2073fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715aa628-7cb4-4a8d-9583-8cfc4e31f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the URL of the YouTube channel you want to extract videos from\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the channel URL and parse the HTML content\n",
    "response = requests.get(channel_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all the video title elements on the channel page\n",
    "title_elements = soup.find_all(\"a\", {\"class\": \"yt-simple-endpoint style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "first_five_video_titles = []\n",
    "for title in title_elements[:5]:\n",
    "    video_title = title.text\n",
    "    first_five_video_titles.append(video_title)\n",
    "\n",
    "# Print the titles of the first five videos\n",
    "for idx, video_title in enumerate(first_five_video_titles, start=1):\n",
    "    print(f\"Video {idx} Title: {video_title.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b9c980-b558-4d7c-979f-ac7d6b4ecad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d7d719-3d31-49be-b7a7-8136adce822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the URL of the YouTube channel you want to extract videos from\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the channel URL and parse the HTML content\n",
    "response = requests.get(channel_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all the video view count elements on the channel page\n",
    "view_count_elements = soup.find_all(\"span\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the view counts of the first five videos\n",
    "first_five_video_view_counts = []\n",
    "for view_count in view_count_elements[:5]:\n",
    "    view_count_text = view_count.text.strip()\n",
    "    if \"views\" in view_count_text:\n",
    "        first_five_video_view_counts.append(view_count_text)\n",
    "\n",
    "# Print the view counts of the first five videos\n",
    "for idx, view_count in enumerate(first_five_video_view_counts, start=1):\n",
    "    print(f\"Video {idx} View Count: {view_count}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e8efb4-8b58-4175-af59-b65609c1e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d94443-3e2f-4d9d-9ad1-1d7f9b6359be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the URL of the YouTube channel you want to extract videos from\n",
    "channel_url = \"https://www.youtube.com/c/PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the channel URL and parse the HTML content\n",
    "response = requests.get(channel_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all the video timestamp elements on the channel page\n",
    "timestamp_elements = soup.find_all(\"yt-formatted-string\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the timestamps of the first five videos\n",
    "first_five_video_timestamps = []\n",
    "for timestamp in timestamp_elements[:5]:\n",
    "    timestamp_text = timestamp.text.strip()\n",
    "    if \"ago\" in timestamp_text:\n",
    "        first_five_video_timestamps.append(timestamp_text)\n",
    "\n",
    "# Print the timestamps of the first five videos\n",
    "for idx, video_timestamp in enumerate(first_five_video_timestamps, start=1):\n",
    "    print(f\"Video {idx} Timestamp: {video_timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4b611-54b6-452d-9123-29b88b7c178c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
